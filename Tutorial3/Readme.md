## Tutorial 2: Probabilistic Convergence Visualization

by *Suwichaya Suwanwimolkul, Ph.D.*

The coding exercies and examples are used as parts of  *Probabilistic Convergence* in **Estimation Theory EE2102523**.  

Let's start  
<a target="_blank" href="https://colab.research.google.com/github/GenAI-CUEE/Estimation-Theory-EE523/blob/master/Tutorial3/main.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

or you can run `main.ipynb` locally for the coding exercies and examples.


The topics covered in this exercise are: 
- [Convergence in Distribution](#convergences-in-distribution)
    - [Simulation of Central Limit Theorem](#simulation-of-central-limit-theorem-bernoulli--uniform)
    - [KL Divergence](#kl-divergence)
- [Convergence in Probability](#convergence-in-probability)
    - [Simulation of Lecture II Example](#simulation-of-example---noise-in-lecture-2)
- [Almost Sure Convergence](#almost-surely-converge)
    - [Converge almost completely](#converges-almost-completely)
    - [Simulation of HW 2.1.3](#simulation-for-the-3rd-question-of-example-16) 


### Quick start 

You can also try everything on your local machine by ...


Install dependenies listed in `requirements.txt` by 

```
pip install -r requirements.txt
```

Then, start the jupyternote book [`main.ipynb`](main.ipynb).
 

 
### Final Notes.
-  Don't forget to install the dependency `pip install -r requirements.txt`
- `utils.py` contains the supplenmary implementations for each fucntion used in `main.ipynb` 
- Good luck! 